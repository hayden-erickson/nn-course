{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Backpropagation\n",
    "\n",
    "This is how our network performs gradient descent. By treating the network as a chain of functions we can use the chain rule to find the gradients for every single weight. Using the gradients, we can update the weights and biases and make the network perform slightly better. We repeat this process until the network stops improving or after a fixed number of iterations. \n",
    "\n",
    "So what is our actual chain of operations that we will have our network perform? The first operation is to multiply the weights by our input and add the biases. The second is the activation function which takes in the output of the previous operation. The third is the cost function which takes in the output of the activation function. This would be the exact steps if we had a network with only one layer. If we use more layers we just repeat the first two steps for each layer.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "& \\quad x = input \\\\\n",
    "\\mathrm{(1)} & \\quad z(x) = wx + b  \\\\\n",
    "\\mathrm{(2)} & \\quad a(z) = \\text{we could use sigmoid, relu, linear, or any other activation} \\\\\n",
    "\\mathrm{(3)} & \\quad C(a) = \\frac{1}{2}\\|y - a\\|^2\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We ultimately want to lower the cost or make the answers the network gives us closer to their actual value which we get from our labeled data. Therefore, we want to find the gradient of the cost function and use that to get the gradients of our weights and biases with respect to the cost. In other words we will find out what effect each weight and bias has on the cost function. This effect represents the slope of the cost function in the dimension of a particular weight or bias. That slope is what we want to \"roll\" down by subtracting it from the particular weight.\n",
    "\n",
    "How can we compute the gradient for the weights in our network? It is similar to how we found the gradients for the slope and y intercept of our best fit line in the previous module except we have one extra step which is the activation function.\n",
    "\n",
    "The gradients for the weights and biases in our weighted input function, number 1 above, is the same as with our best fit line. The gradient for the cost function is the same as well. The only difference is now we need to know the gradient of the activation function. However, once we have that, we can find the gradients for all the weights and biases.\n",
    "\n",
    "We find the gradients for every step in our chain\n",
    "\n",
    "\\begin{align}\n",
    "x & = \\text{input} \\\\\n",
    "y & = \\text{input label or \"correct answer\"} \\\\\n",
    "\\frac{\\partial z}{\\partial w} & = x \\\\\n",
    "\\frac{\\partial z}{\\partial b} & = 1 \\\\\n",
    "\\frac{\\partial a}{\\partial z} & = a'(z) \\\\\n",
    "\\frac{\\partial C}{\\partial a} & = a - y\n",
    "\\end{align}\n",
    "\n",
    "For each of our activation functions we can find the derivative or gradient in the following way. The functions listed are linear, relu, and sigmoid respectively.\n",
    "\n",
    "\\begin{align}\n",
    "y(z) & = z \\\\\n",
    "y'(z) & = 1 \\\\\n",
    "relu(z) & = \\begin{cases}\n",
    "    z & \\quad \\text{if } z \\text{ > 0} \\\\\n",
    "    0 & \\quad \\text{if } z \\text{ <= 0}\n",
    "    \\end{cases} \\\\\n",
    "relu'(z) & = \n",
    "    \\begin{cases}\n",
    "    1 & \\quad \\text{if } z \\text{ > 0} \\\\\n",
    "    0 & \\quad \\text{if } z \\text{ <= 0}\n",
    "    \\end{cases} \\\\\n",
    "\\sigma(z) & = \\frac{1}{1+e^{-z}} \\\\\n",
    "\\sigma'(z) & = \\sigma(z)(1 - \\sigma(z))\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We can chain the gradients together to find what we really want which is the gradients for each weight and bias in the cost function. In other words, how much does a change in the weight or bias affect the final cost and in what direction (positive or negative). Using this value, we can subtract it from the weight or bias to make it \"roll\" down the hill. \n",
    "\n",
    "So the expression $\\frac{\\partial C}{\\partial w}$ really means what is the change in cost (top) divided by the change in weight (bottom). Or $\\frac{\\partial C}{\\partial b}$ means what is the change in final cost over the change in a certain bias. These values tell us how much a change in the weight or bias affects the final cost and whether that relationship is positive or negative. \n",
    "\n",
    "If the relationship is positive that means we have a positive slope and as our weight or bias increases, so too does our cost. Alternatively, if the relationship is negative then as one goes up the other goes down. The magnitude of this value represents how big of a change will happen or how steep our slope is. In that sense it tells us the steepness and direction of the hill. \n",
    "\n",
    "So when we chain the gradients together for each of our steps, we can find those slopes.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial w} & =  \\frac{\\partial C}{\\partial a} \\frac{\\partial a}{\\partial z} \\frac{\\partial z}{\\partial w} & = x a'(z) (a - y)\\\\\n",
    "\\frac{\\partial C}{\\partial b} & = \\frac{\\partial C}{\\partial a} \\frac{\\partial a}{\\partial z} \\frac{\\partial z}{\\partial b} & = a'(z) (a - y) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Can you see how the tops and bottoms of the fractions in the middle cancel out to give us the left hand side of each equation? All of the a'(z) terms above can be replaced with the corresponding derivative of whichever activation function we decide to use. For instance if we're using the linear activation function, the $a'(z)$ just becomes 1.\n",
    "\n",
    "Let's see if we can train a single layer network to predict house prices. This layer will only have 1 output for price and we will use a linear activation function. \n",
    "\n",
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset = load_boston()\n",
    "\n",
    "# The house features are essentially a table with 13 columns\n",
    "# each column is described in the dataset\n",
    "house_features = dataset.data\n",
    "house_prices = dataset.target\n",
    "\n",
    "print(dataset.keys())\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Layer\n",
    "\n",
    "To start with this problem of predicting house prices we have to build a network with only 1 layer and only 1 neuron.\n",
    "\n",
    "![1layer](img/1-layer.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted price: $31978.54, actual price: $12700.00\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, num_inputs, num_neurons):\n",
    "        # we now have 1 row per neuron and 1 column per weight\n",
    "        self.weights = np.random.uniform(-.1, .1, size=(num_neurons, num_inputs))\n",
    "\n",
    "        # we also randomly create a bias for each neuron\n",
    "        self.biases = np.random.uniform(-.1, .1, size=num_neurons)\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.weights.dot(inputs) + self.biases\n",
    "\n",
    "            \n",
    "    \n",
    "# create a layer with the same number of inputs as there are features in our data\n",
    "# and with only 1 output for the price\n",
    "all_inputs = Layer(len(dataset.feature_names), 1)\n",
    "\n",
    "# randomly pick a house from the dataset\n",
    "house_idx = randint(0, len(dataset.data)-1)\n",
    "\n",
    "# get the features and price of the house\n",
    "house = house_features[house_idx]\n",
    "price = house_prices[house_idx]\n",
    "\n",
    "# have our layer predict a price for the house\n",
    "predicted_price = all_inputs.predict(house)[0]\n",
    "\n",
    "print('predicted price: ${:.2f}, actual price: ${:.2f}'.format(predicted_price * 1000, price * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously the layer is not very good because we have not taught it anything. This is where gradient descent comes in. Now for every example in our data we can find the gradients and use them to update our layer. So we have 4 gradients to find for each input example\n",
    "\n",
    "\\begin{align}\n",
    "1. \\quad \\frac{\\partial z}{\\partial w} & = \\text{What effect does a change in our weight have on the output of the weighted input} \\\\\n",
    "2. \\quad \\frac{\\partial z}{\\partial b} & = \\text{What effect does a change in our bias have on the output of the weighted input} \\\\\n",
    "3. \\quad \\frac{\\partial a}{\\partial z} & = \\text{What effect does a change in our weighted input have on the output of the activation function} \\\\\n",
    "4. \\quad \\frac{\\partial C}{\\partial a} & = \\text{What effect does a change in our activation have on the output of the cost function}\n",
    "\\end{align}\n",
    "\n",
    "We multiply gradients (1, 3, 4) above for the weight gradient and gradients (2, 3, 4) for the biases for every input example. Multiply by the learning rate, and subtract it from the weights or biases. We are using the linear activation function so gradient 3 $\\quad \\frac{\\partial a}{\\partial z} = 1$ and we can basically ignore it because anything multiplied by 1 is just itself.\n",
    "\n",
    "We already saw in the last module that $\\frac{\\partial z}{\\partial w}$ is just $x$ or our input and $\\frac{\\partial z}{\\partial b}$ is just 1. After ignoring all the 1's we are left with only 2 gradients we need to find.\n",
    "\n",
    "\\begin{align}\n",
    "1. \\quad \\frac{\\partial z}{\\partial w} & = x \\\\\n",
    "2. \\quad \\frac{\\partial C}{\\partial a} & = a - y\n",
    "\\end{align}\n",
    "\n",
    "Then to find the gradients of our weights and biases we just do\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\text{weights} \\quad \\frac{\\partial C}{\\partial w} = \\frac{\\partial C}{\\partial a} \\frac{\\partial a}{\\partial z} \\frac{\\partial z}{\\partial w} = (a-y) * 1 * x = x (a-y) \\\\\n",
    "\\text{biases} \\quad \\frac{\\partial C}{\\partial b} = \\frac{\\partial C}{\\partial a} \\frac{\\partial a}{\\partial z} \\frac{\\partial z}{\\partial b} = (a-y) * 1 * 1 = (a-y)\n",
    "\\end{align}\n",
    "\n",
    "Where $a$ is the output activation of our layer (i.e. the predicted price), $x$ is just the input (i.e. the house features), and $y$ is the target value (i.e. the correct house price). Numpy also allows us to do a fancy trick where we can take two lists and subtract them which in turn just performs element-wise subtraction. Similarly, if we multiply two numpy arrays, it will just do element-wise multiplication. Therefore, we can find the gradients for all input examples without needing to iterate over them.\n",
    "\n",
    "In the next example we also introduce input normalization. This takes all input features and rescales them. The normalize function specifically uses an l2 norm. If we then look at a specific house example, we have rescaled all the features of it so that when we use the pythagorean theorum across all features, it equals 1. Since there are 13 features, it would be like $\\sqrt{a^2 + b^2 + c^2 + ... + m^2} = 1$\n",
    "\n",
    "There are a couple reasons for doing this. One is that it makes all the numbers MUCH smaller. That lets us deal with smaller numbers when we update the gradients of the weights and biases which prevents overflow values from accumulating. Also it makes the training much much faster because we no longer have to deal with operations on massive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== BEFORE TRAINING ======\n",
      "cost: 197.75\n",
      "\n",
      "predicted\tactual\n",
      "---------------------\n",
      "0.13\t\t20.40\n",
      "0.13\t\t19.80\n",
      "0.13\t\t19.40\n",
      "0.13\t\t21.70\n",
      "0.12\t\t22.80\n",
      "0.13\t\t18.80\n",
      "0.13\t\t18.70\n",
      "0.12\t\t18.50\n",
      "0.12\t\t18.30\n",
      "0.12\t\t21.20\n",
      "\n",
      "\n",
      "====== AFTER TRAINING ======\n",
      "cost: 1.99\n",
      "\n",
      "predicted\tactual\n",
      "---------------------\n",
      "21.98\t\t20.40\n",
      "22.04\t\t19.80\n",
      "21.88\t\t19.40\n",
      "22.66\t\t21.70\n",
      "21.65\t\t22.80\n",
      "21.18\t\t18.80\n",
      "21.15\t\t18.70\n",
      "21.45\t\t18.50\n",
      "20.13\t\t18.30\n",
      "21.65\t\t21.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "\n",
    "def cost(y, a):\n",
    "    return (1/2)*(y - a)**2\n",
    "\n",
    "\n",
    "def get_predictions(input_data, predictor):\n",
    "    return [predictor(x)[0] for x in input_data]\n",
    "\n",
    "\n",
    "# take our 10 examples along with their 10 corresponding \n",
    "# predictions and find the cost for each one, then take the average\n",
    "def find_avg_cost(test_set, test_labels, predictor):\n",
    "    test_a = get_predictions(test_set, predictor)\n",
    "    test_costs = [cost(y, a) for (y, a) in zip(test_labels, test_a)]\n",
    "    return sum(test_costs)/len(test_costs)\n",
    "\n",
    "def evaluate_predictor(test_set, actual_values, predictor, N=10):\n",
    "    print('cost: {:.2f}'.format(find_avg_cost(test_set, actual_values, predictor)))\n",
    "    \n",
    "    trained_predictions = get_predictions(test_set, predictor)\n",
    "    \n",
    "    print('\\npredicted\\tactual')\n",
    "    print('---------------------')\n",
    "    print('\\n'.join('{:.2f}\\t\\t{:.2f}'\\\n",
    "                    .format(a, y) for (a, y) in zip(trained_predictions, actual_values)))\n",
    "\n",
    "def train(layer, data, labels, learning_rate):\n",
    "    for i in range(1000):\n",
    "        a = [layer.predict(x)[0] for x in data]\n",
    "\n",
    "        # every element in dC/db is just a single value \n",
    "        # representing the gradient for the single bias \n",
    "        # because we only have 1 neuron. There are 506\n",
    "        # gradient values, 1 for each example\n",
    "        dC_db = a - labels\n",
    "\n",
    "        # every element in dC/dw has 13 values, 1 for \n",
    "        # each weight in our layer. There are 506\n",
    "        # elements, 1 for each example\n",
    "        dC_dw = (data.transpose() * (a - labels)).transpose()\n",
    "\n",
    "        # THIS IS THE ACTUAL LEARNING PART!!!\n",
    "        layer.biases -= dC_db.mean()*learning_rate\n",
    "\n",
    "        # here the axis 0 means we want to take the \n",
    "        # mean of every column so we're left with 13 \n",
    "        # means and not just one mean of every value \n",
    "        # in the list\n",
    "        layer.weights -= dC_dw.mean(axis=0)*learning_rate\n",
    "\n",
    "# The all inputs layer is going to use all input columns\n",
    "# to predict house price\n",
    "layer = Layer(len(dataset.feature_names), 1)\n",
    "\n",
    "\n",
    "# try out different learning rates and see how horrible it can get\n",
    "learning_rate = .6\n",
    "\n",
    "house_features_normalized = normalize(house_features)\n",
    "\n",
    "test_start = randint(0, len(house_features_normalized) - 10)\n",
    "\n",
    "test_set = house_features_normalized[test_start:test_start+10]\n",
    "actual_values = house_prices[test_start:test_start+10]\n",
    "\n",
    "\n",
    "print('====== BEFORE TRAINING ======')\n",
    "evaluate_predictor(test_set, actual_values, layer.predict)\n",
    "\n",
    "train(layer, house_features_normalized, house_prices, learning_rate)\n",
    "\n",
    "print('\\n\\n====== AFTER TRAINING ======')\n",
    "evaluate_predictor(test_set, actual_values, layer.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 1 To N Layers\n",
    "\n",
    "IT LEARNS!!! Our cost always gets smaller and our prices are getting closer!!! That means our network is actually getting better at predicting house prices!!!\n",
    "\n",
    "However, this network only has 1 layer. How might we find the gradients if we have more than 1 layer. We can continue to use the chain rule just as we did before, we just need to add an extra step. This is what our chain of operations looks like when we go from 1 to 2 layers.\n",
    "\n",
    "![title](img/layers.svg)\n",
    "\n",
    "We know the gradients for the weighted input $\\frac{\\partial z}{\\partial w}$ and $\\frac{\\partial z}{\\partial b}$, activation functions $\\frac{\\partial a}{\\partial z}$, and cost function $\\frac{\\partial C}{\\partial a}$. Now we just have to find the gradient between the two layers. The input to layer 2 is the output of layer 1. The first operation in layer 2 is the weighted input operation and its input is the activation function output of layer 1.\n",
    "\n",
    "We want to know how the input to the weighted input function affects it's output. Before our gradients $\\frac{\\partial z}{\\partial w}$ and $\\frac{\\partial z}{\\partial b}$ told us how the weights and biases affect the output, but now we want $\\frac{\\partial z}{\\partial x}$ where x is the output from layer 1. If we replace the variable $x$ with $a$ so that we know our intput represents and activation we get the following gradient for the equation $z(a) = wa + b$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial z}{\\partial a} = w\n",
    "\\end{equation*}\n",
    "\n",
    "In this case $w$ represents our slope and tells us how much a change to $a$ will affect the output of $z(a)$. Now we can simply add this gradient into our chain to find the gradients for the weights and biases of each layer.\n",
    "\n",
    "Now that we have multiple layers we need to identify which weights and biases we're talking about, the ones from layer 1 or 2. Therefore, from now on when we refer to the weights, biases, or activations we will add a superscript that indicates which layer they are in. The steps to find the gradients for layer one are as follows.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial C}{\\partial w^{L1}} = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial a^{L1}} \\frac{\\partial a^{L1}}{\\partial z^{L1}} \\frac{\\partial z^{L1}}{\\partial w^{L1}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can see that the fraction or gradient $\\frac{\\partial z^{L2}}{\\partial a^{L1}}$ represents the effect that the output activation of $L1$ has on the output from the weighted input of $L2$. This term is precisely how we can allow our gradients to propagate backwards across multiple layers, hence backpropagation. However, this is really just the chain rule which we're using because we have a chain of operations where the output from one goes on to be the input of the next. The equation for the biases in $L1$ is the same except for the very last term which we replace with $\\frac{\\partial z^{L1}}{\\partial b^{L1}}$ and we've already determined that this term is just 1 so you can ignore it if you like.\n",
    "\n",
    "Now we just need the gradients for the weights and biases in $L2$ which will look very similar to our network with only one layer. The gradient terms we would like to find are $\\frac{\\partial C}{\\partial w^{L2}}$ and $\\frac{\\partial C}{\\partial b^{L2}}$ and we can do so as follows.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial C}{\\partial w^{L2}} = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial w^{L2}}\n",
    "\\end{equation*}\n",
    "\n",
    "Just as before, by replacing the laste term $\\frac{\\partial z^{L2}}{\\partial w^{L2}}$ with $\\frac{\\partial z^{L2}}{\\partial b^{L2}}$ we can obtain the gradients for the $L2$ biases. Ultimately, the value of $\\frac{\\partial z^{L2}}{\\partial b^{L2}}$ is just 1 therefore we can essentially ignore it.\n",
    "\n",
    "# Putting It All Together\n",
    "\n",
    "We now have all the information we need to find the gradients of the weights and biases for every layer in our network. We have only explicitly mentioned 2 layers, but this process of chaining gradients together can be repeated for any number of layers.\n",
    "\n",
    "It's killing me!!! what are the final gradient values substituting each respective term in our chain??? If we continue to use the linear activation function, all gradients are just 1. However, if we used another activation function we could replace the 1 with the derivative of whichever activation function we choose.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial w^{L1}} & = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial a^{L1}} \\frac{\\partial a^{L1}}{\\partial z^{L1}} \\frac{\\partial z^{L1}}{\\partial w^{L1}}  = (Y - a^{L2}) * 1 * w^{L2} * 1 * x  = (Y - a^{L2}) * w^{L2} * x \\\\\n",
    "\\frac{\\partial C}{\\partial b^{L1}} & = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial a^{L1}} \\frac{\\partial a^{L1}}{\\partial z^{L1}} \\frac{\\partial z^{L1}}{\\partial b^{L1}} = (Y - a^{L2}) * 1 * w^{L2} * 1 * 1  = (Y - a^{L2}) * w^{L2} \\\\\n",
    "\\frac{\\partial C}{\\partial w^{L2}} & = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial w^{L2}} = (Y - a^{L2}) * 1 * a^{L1} = (Y - a^{L2}) * a^{L1} \\\\\n",
    "\\frac{\\partial C}{\\partial b^{L2}} & = \\frac{\\partial C}{\\partial a^{L2}} \\frac{\\partial a^{L2}}{\\partial z^{L2}} \\frac{\\partial z^{L2}}{\\partial b^{L2}} = (Y - a^{L2}) * 1 * 1 = (Y - a^{L2})  \\\\\n",
    "\\end{align}\n",
    "\n",
    "Just for the sake of clarity I will remove all of the substitution and canceling\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial w^{L1}} & = (Y - a^{L2}) * w^{L2} * x \\\\\n",
    "\\frac{\\partial C}{\\partial b^{L1}} & = (Y - a^{L2}) * w^{L2} \\\\\n",
    "\\frac{\\partial C}{\\partial w^{L2}} & = (Y - a^{L2}) * a^{L1} \\\\\n",
    "\\frac{\\partial C}{\\partial b^{L2}} & = (Y - a^{L2})  \\\\\n",
    "\\end{align}\n",
    "\n",
    "And finally because I told you we could do this with any number of layers, here are the generic equations where $1 <= K < N$ and $N$ is our number of layers. Remember the super script of each term just says which layer we're talking about and the fractions are just the effect that a particular input (the denominator) has on the output (the numerator) of that step in the chain. \n",
    "\n",
    "The right 2 terms tell us what effect the weights in layer $K$ have on the output activation of layer $K$. The middle term in parenthesis gets expanded for each subsequent layer. In english the middle term tells us what effect the activation from layer $K$ has on the output activation of layer $K+1$ up to $N$ and the last term tells us what effect the output activation from layer $N$ has on the cost function. The funky $\\prod$ symbol just means multiply everything together.\n",
    "\n",
    "I like to think about the top and bottom terms canceling when they are the same. In other words dividing something by itself just gives you 1. Therefore, we can add as many terms in the middle series as we want because their numerators and denominators cancel out.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial C}{\\partial w^K} = \\frac{\\partial C}{\\partial a^N} * \\left(\\prod_{l = K + 1}^{N} \\frac{\\partial a^l}{\\partial z^l} * \\frac{\\partial z^l}{\\partial a^{l-1}}\\right) * \\frac{\\partial a^K} {\\partial z^K} * \\frac{\\partial z^K}{\\partial w^K}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "# Let's Do It!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== BEFORE TRAINING ======\n",
      "cost: 106.50\n",
      "\n",
      "predicted\tactual\n",
      "---------------------\n",
      "-0.08\t\t13.30\n",
      "-0.08\t\t17.80\n",
      "-0.08\t\t14.00\n",
      "-0.08\t\t14.40\n",
      "-0.08\t\t13.40\n",
      "-0.08\t\t15.60\n",
      "-0.08\t\t11.80\n",
      "-0.08\t\t13.80\n",
      "-0.08\t\t15.60\n",
      "-0.08\t\t14.60\n",
      "\n",
      "====== AFTER TRAINING ======\n",
      "cost: 13.48\n",
      "\n",
      "predicted\tactual\n",
      "---------------------\n",
      "19.78\t\t13.30\n",
      "19.97\t\t17.80\n",
      "19.65\t\t14.00\n",
      "19.41\t\t14.40\n",
      "20.16\t\t13.40\n",
      "20.17\t\t15.60\n",
      "20.10\t\t11.80\n",
      "14.64\t\t13.80\n",
      "15.01\t\t15.60\n",
      "20.01\t\t14.60\n"
     ]
    }
   ],
   "source": [
    "class Network:\n",
    "    def __init__(self, *layers, cost_fn=cost):\n",
    "        self.layers = layers\n",
    "        self.dz_dw = []\n",
    "        \n",
    "    def predict(self, x):\n",
    "        dz_dw = [x]\n",
    "        prediction = x\n",
    "\n",
    "        for l in self.layers:\n",
    "            prediction = l.predict(prediction)\n",
    "            dz_dw.append(prediction)\n",
    "\n",
    "        self.dz_dw = dz_dw\n",
    "\n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    def get_gradient(self, x, y):\n",
    "        # find the gradient for a single example\n",
    "        prediction = self.predict(x)\n",
    "        # get the gradient of the cost function\n",
    "        dC_da = prediction - y\n",
    "\n",
    "        dC_dw = []\n",
    "        dC_db = []\n",
    "\n",
    "        # loop over the layers in reverse using python's handy\n",
    "        # negative list index where list[-1] is the last element,\n",
    "        # list[-2] is second to last, and so on.\n",
    "        for i in range(1, len(self.layers)+1):\n",
    "            dC_dz = dC_da\n",
    "            # always insert the weight and bias gradients in the\n",
    "            # beginning of the list b/c we're going in reverse\n",
    "            # that way, when we're done, the gradients are in\n",
    "            # forward order as they appear in the network\n",
    "            dC_dw.insert(0, np.outer(dC_dz, self.dz_dw[-(i+1)]))\n",
    "            dC_db.insert(0, dC_dz)\n",
    "            dC_da = self.layers[-i].weights.transpose().dot(dC_dz)\n",
    "\n",
    "        return dC_dw, dC_db\n",
    "\n",
    "\n",
    "def train(net, features, labels, epochs, learning_rate):\n",
    "    for epoch in range(epochs):\n",
    "        for (house, price) in zip(features, labels):\n",
    "                dC_dws, dC_dbs = net.get_gradient(house, price)\n",
    "                # THIS IS THE LEARNING\n",
    "                # here we update all the weights and biases\n",
    "                for j in range(len(net.layers)):\n",
    "                    net.layers[j].weights -= dC_dws[j] * learning_rate\n",
    "                    net.layers[j].biases -= dC_dbs[j].flatten() * learning_rate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_inputs = len(house_features[0])\n",
    "num_neurons_l1 = 5\n",
    "num_neurons_l2 = 3\n",
    "\n",
    "l1 = Layer(num_inputs, num_neurons_l1)\n",
    "l2 = Layer(num_neurons_l1, num_neurons_l2)\n",
    "l3 = Layer(num_neurons_l2, 1)\n",
    "\n",
    "net = Network(l1, l2, l3)\n",
    "\n",
    "\n",
    "test_start = randint(0, len(house_features)-10)\n",
    "test_set = house_features_normalized[test_start:test_start+10]\n",
    "actual_values = house_prices[test_start:test_start+10]\n",
    "\n",
    "# The learning rate is so small because of\n",
    "# the exploding gradient problem. As we backpropagate\n",
    "# the gradients, we multiply by the weights in each \n",
    "# layer and sum. As you can imagine repeatedly multiplying\n",
    "# and adding can grow very quickly! Therefore, to prevent\n",
    "# the gradients from running off to infinity, we must scale \n",
    "# them down heavily.\n",
    "learning_rate = .00005\n",
    "\n",
    "print('\\n====== BEFORE TRAINING ======')\n",
    "evaluate_predictor(test_set, actual_values, net.predict)\n",
    "\n",
    "train(net, house_features_normalized, house_prices, 200, learning_rate)\n",
    "\n",
    "print('\\n====== AFTER TRAINING ======')\n",
    "evaluate_predictor(test_set, actual_values, net.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Visual of what we just made\n",
    "\n",
    "This is the image of the network from the previous example. The weight matricies show how the dimensions line up. The rows of the matrix match the number of neurons on the output side while the columns correspond to the neurons on the input side. Now that you know what each component of the network is, a great online visualization is available [here](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.99090&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) \n",
    "\n",
    "\n",
    "![net-example](img/net-example.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
